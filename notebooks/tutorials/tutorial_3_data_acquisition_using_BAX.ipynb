{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, Matern, RBF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "os.chdir(\"../../\") # cell can only be run once! \n",
    "\n",
    "from src.utils import XY_from_csv, random_sampling_no_replace, load_ternary_data\n",
    "from src.acquisition import run_acquisition\n",
    "from src.algorithms import MultibandUnion, ConditionalMultiband, MultibandIntersection, ParetoPlusMultiband, ParetoFront, Wishlist, PercentileSet1D\n",
    "from src.models import MGPR, fit_matern_hypers\n",
    "from src.metrics import get_n_obtained, get_jaccard_posterior\n",
    "from src.plotting import plot_final_metrics, plot_iteration_results, plot_algo_true_function\n",
    "\n",
    "plt.style.use(\"src/matplotlib.rc\")\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load / download datasets for ternary phase diagram of Fe-Ni-Co [1, 2]: \n",
    "\n",
    "[1] Yoo, Young-kook et al. “Identification of amorphous phases in the Fe–Ni–Co ternary alloy system using continuous phase diagram material chips.” Intermetallics 14 (2006): 241-247 (https://www.sciencedirect.com/science/article/pii/S096697950500186X).\n",
    "\n",
    "[2] Alex Wang, Haotong Liang, Austin McDannald, Ichiro Takeuchi, Aaron Gilad Kusne, Benchmarking active learning strategies for materials optimization and discovery, Oxford Open Materials Science, Volume 2, Issue 1, 2022, itac006, https://doi.org/10.1093/oxfmat/itac006 (https://academic.oup.com/ooms/article/2/1/itac006/6637521).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/usnistgov/remi/raw/nist-pages/data/Combinatorial%20Libraries/Fe-Co-Ni/FeCoNi_benchmark_dataset_220501a.mat\n",
    "!mkdir datasets\n",
    "!mv FeCoNi_benchmark_dataset_220501a.mat datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_ternary_data('datasets/FeCoNi_benchmark_dataset_220501a.mat')\n",
    "\n",
    "n_features, n_properties = X.shape[1], Y.shape[1]\n",
    "\n",
    "print(\"Size of the design space: {}, Size of the measured property space: {}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize datasets (in order to get GP models to fit well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "scalers = [x_scaler, y_scaler]\n",
    "\n",
    "X = x_scaler.fit_transform(X)\n",
    "Y = y_scaler.fit_transform(Y)\n",
    "\n",
    "X_unnorm, Y_unnorm = x_scaler.inverse_transform(X), y_scaler.inverse_transform(Y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define experimental goals via algorithms. Here, we select a Wishlist Algorithm (disjoint set of multibands [[a, b], [c, d]]; i.e. where a < y1 < b AND c < y2 < d). \n",
    "\n",
    "Please refer to tutorial <code>tutorial_1_expressing_a_goal_as_an_algorithm</code> for guidance on how to define a custom algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    'Wishlist': Wishlist(user_algo_params={'scalers': scalers, 'threshold_bounds_list': [[[0.0, 2.0], [0.00, 0.2]], [[8.0, 10.0], [0.0, 0.1]], [[5.0, 8.0], [0.3, 0.5]]]}),\n",
    "    'Robust Pareto Front': ParetoFront(user_algo_params={'scalers': scalers, 'max_or_min_list': [1, 1], 'tolerance_list': [0.1, 0.1]}),\n",
    "    'Multiband': MultibandIntersection(user_algo_params={'scalers': scalers, 'threshold_bounds': [[2.5, 3.0], [0.3, 0.4]]}),\n",
    "    'ParetoPlusMultiband': ParetoPlusMultiband(user_algo_params={'scalers': scalers, 'max_or_min_list': [1, 1], 'tolerance_list': [0.001, 0.001], 'threshold_bounds': [[2.5, 3.0], [0.3, 0.4]]})\n",
    "}\n",
    "\n",
    "# Create a dropdown widget for algorithm selection\n",
    "algorithm_name_dropdown = widgets.Dropdown(\n",
    "    options=list(algorithms.keys()),\n",
    "    value=list(algorithms.keys())[0],\n",
    "    description='Algo:'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RERUN cell with different algos!\n",
    "display(algorithm_name_dropdown)\n",
    "algorithm = algorithms[algorithm_name_dropdown.value]\n",
    "plot_algo_true_function(algorithm, x_scaler, y_scaler, X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ground-truth target subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = list(np.arange(0, len(X)))  # integer mapping design space\n",
    "true_target_ids = algorithm.identify_subspace(f_x=Y, x=X) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a GP kernel. Note, in order to use a different kernel, the code below has to be modified to the new kernel AND <code>fit_matern_hypers</code> in src/utils.py needs to be appropriately modified. The reason for this is to ensure that the n_posterior_sample GP models all have identical kernels (for InfoBAX/SwitchBAX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_initial = ConstantKernel(constant_value=1.0, constant_value_bounds=[0.01, 3.0]) * Matern(nu = 5/2, length_scale= n_features * [1.0], length_scale_bounds= n_features * [[0.01, 3.0]]) + WhiteKernel(noise_level=0.01, noise_level_bounds='fixed')\n",
    "kernel_initial_list = n_properties * [kernel_initial]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config params: \n",
    "\n",
    "Note: <code>fixed_hypers = True</code> fits the GP hyperparameters on the entire dataset. For more a more practical scenario, choose <code>fixed_hypers = False</code> which will perform adaptive hyperparameter fitting (a bit slower)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = True\n",
    "prevent_requery = True\n",
    "n_posterior_samples = 15 # relevant for InfoBAX and mixedBAX \n",
    "n_initial = 1 # Number of initial datapoints \n",
    "n_iters = 300 # Number of measurements to be performed \n",
    "plot_frequency = n_iters - 1\n",
    "n_repeats = 2 # Repeats with different dataset initializations \n",
    "fixed_hypers = True \n",
    "adaptive_fit_freq = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below simulates data acquisition for a specific experimental goal using the following acquisition functions: SwitchBAX, MeanBAX, InfoBAX and US. Adding additional repeats selects different initial starting training points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"SwitchBAX\": {\"n_obtained\": [], \"jaccard_posterior_index\": [], \"switch_strategy\": []},\n",
    "    \"US\": {\"n_obtained\": [], \"jaccard_posterior_index\": [], \"switch_strategy\": []},\n",
    "    \"MeanBAX\": {\"n_obtained\": [], \"jaccard_posterior_index\": [], \"switch_strategy\": []},\n",
    "    \"InfoBAX\": {\"n_obtained\": [], \"jaccard_posterior_index\": [], \"switch_strategy\": []},\n",
    "}\n",
    "\n",
    "# Baseling for random sampling without replacement (expectation of hypergeometric distribution)\n",
    "random_sampling = [random_sampling_no_replace(len(X), len(true_target_ids), n) for n in range(n_initial, n_iters)]\n",
    "\n",
    "# Baseline for best possible acquisition (i.e. acquire a target point at each iteration; need an \"oracle\" to do this)\n",
    "if n_iters <= len(true_target_ids):\n",
    "    best_possible_n_obtained = np.arange(n_initial, n_iters + n_initial)\n",
    "else:\n",
    "    best_possible_n_obtained = list(np.arange(n_initial, len(true_target_ids))) + list(\n",
    "        len(true_target_ids) * np.ones(n_iters + n_initial - len(true_target_ids))\n",
    "    )\n",
    "\n",
    "# Acquisition functions that use BAX for subset estimation\n",
    "strategies = [\"SwitchBAX\", \"MeanBAX\", \"US\", \"InfoBAX\"]\n",
    "\n",
    "\n",
    "# Calculate hypers based on the entire dataset; this is not possible in a real experiment but allows us to compare acquisition fn to acquisition fn\n",
    "if fixed_hypers: kernel_list = fit_matern_hypers(x_train=X, y_train=Y, kernel_list=kernel_initial_list, n_restarts_optimizer=1)\n",
    "\n",
    "for strategy in strategies:    \n",
    "    for j in range(n_repeats):  # to see variance w.r.t initial datapoint choice\n",
    "        \n",
    "        print(\"Using strategy: {}, repeat number: {}\".format(strategy, j))\n",
    "\n",
    "        np.random.seed(j) # make sure all strategies get same initial points\n",
    "        train_indices = list(np.random.choice(all_ids, n_initial))\n",
    "        x_train = X[train_indices]\n",
    "        y_train = Y[train_indices]\n",
    "\n",
    "        collected_ids = list(train_indices)\n",
    "        n_obtained_list = []\n",
    "        jaccard_posterior_list = []\n",
    "        switch_list = [] \n",
    "\n",
    "        for i in tqdm(range(n_iters)):\n",
    "            # Adaptive hyperparameter fitting\n",
    "            if (i % adaptive_fit_freq == 0) and (fixed_hypers == False):\n",
    "                kernel_list = fit_matern_hypers(x_train=x_train, y_train=y_train, kernel_list=kernel_initial_list)\n",
    "            \n",
    "            # Define GP model with fixed, fitted hypers. Note, we need this so that all the n_posterior models for InfoBAX have the same kernel\n",
    "            multi_gpr = MGPR(kernel_list=kernel_list)\n",
    "\n",
    "            # Acquire next index\n",
    "            x_train, y_train, model, collected_ids, acquisition_function, switch_strategy = run_acquisition(\n",
    "                x_train, y_train, X, Y, strategy, algorithm, multi_gpr, collected_ids, n_posterior_samples\n",
    "            )\n",
    "\n",
    "            # Calculate metrics\n",
    "            posterior_mean, posterior_std = model.predict(X)\n",
    "            predicted_target_ids = algorithm.identify_subspace(f_x = posterior_mean, x=X)\n",
    "            n_obtained_list.append(get_n_obtained(collected_ids, true_target_ids))\n",
    "            jaccard_posterior_list.append(get_jaccard_posterior(predicted_target_ids, true_target_ids))\n",
    "            switch_list.append(switch_strategy)\n",
    "\n",
    "            if (i % plot_frequency == 0) and (plotting) and (i != 0):\n",
    "                plot_iteration_results(\n",
    "                    X,\n",
    "                    Y,\n",
    "                    x_scaler,\n",
    "                    y_scaler,\n",
    "                    collected_ids,\n",
    "                    true_target_ids,\n",
    "                    predicted_target_ids,\n",
    "                    acquisition_function,\n",
    "                    n_obtained_list,\n",
    "                    jaccard_posterior_list,\n",
    "                    best_possible_n_obtained,\n",
    "                    random_sampling,\n",
    "                    n_initial\n",
    "                )\n",
    "\n",
    "        metrics[strategy][\"n_obtained\"].append(n_obtained_list)\n",
    "        metrics[strategy][\"jaccard_posterior_index\"].append(jaccard_posterior_list)\n",
    "        metrics[strategy][\"switch_strategy\"].append(switch_list)\n",
    "\n",
    "plot_final_metrics(n_iters, metrics, strategies, best_possible_n_obtained, random_sampling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89b5c5be7d9a5b6c117ecb4d0f9593b952cdb99d9e5b93dbe620fac69234b982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
