{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "import os \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, Matern\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(\"/Users/satya/Documents/sklearn-bax/\")\n",
    "plt.style.use(\"mpl_style/matplotlib.rc\")\n",
    "\n",
    "from src.utils import XY_from_csv, random_sampling_no_replace\n",
    "from src.acquisition import run_acquisition\n",
    "from src.algorithms import MultiRegionSetUnion, MultiRegionSetIntersection, GlobalOptimization1D, ParetoFront, Wishlist\n",
    "from src.models import MGPR, fit_hypers\n",
    "from src.metrics import get_n_obtained, get_jaccard_posterior\n",
    "from src.plotting import plot_final_metrics, plot_iteration_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = XY_from_csv(\"datasets/ssrl_ternary.csv\", columns_x=[\"c_Fe\",\"c_Co\"], columns_y=[\"coer\", \"kerr\"])\n",
    "\n",
    "\n",
    "x_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scalers = [x_scaler, y_scaler]\n",
    "\n",
    "X = x_scaler.fit_transform(X)\n",
    "Y = y_scaler.fit_transform(Y)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_properties = Y.shape[1]\n",
    "\n",
    "# handles one-property measurements \n",
    "if len(Y.shape) == 1:\n",
    "    Y = Y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm = MultiRegionSetIntersection(threshold_list = [[2.0, 4.0], [0.3, 0.4]], scalers = scalers)\n",
    "\n",
    "algorithm = Wishlist(threshold_bounds = [[[0.0, 2.0], [0.0, 0.2]], [[3.0, 4.0], [0.3, 0.4]], [[8.0, 10.0], [0.0, 0.1]]], scalers = scalers)\n",
    "\n",
    "# algorithm = ParetoFront(tolerance_list = [0.05, 0.01],  max_or_min_list = [1, 1], scalers = scalers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = list(np.arange(0, len(X))) # integer mapping design space\n",
    "true_target_ids = algorithm.identify_subspace(x=X, y=Y) # ground truth set of design points which achieve experimental goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = True\n",
    "prevent_requery = True \n",
    "plot_frequency = 300\n",
    "n_posterior_samples = 20\n",
    "n_initial = 1 \n",
    "n_iters = 301\n",
    "n_repeats = 3\n",
    "fixed_hypers = True\n",
    "adaptive_fit_freq = 10 \n",
    "\n",
    "kernel_initial = ConstantKernel(constant_value = 1.0, constant_value_bounds=[0.01, 2.0]) * Matern(nu = 5/2, length_scale=[0.5, 0.5], length_scale_bounds= 2 * [[0.01, 2.0]]) + WhiteKernel(noise_level=0.01, noise_level_bounds = [0.0001, 0.1])\n",
    "kernel_initial_list = n_properties * [kernel_initial]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 251/301 [07:30<02:19,  2.79s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "metrics = {\"mixed\": {\"n_obtained\": [], \"jaccard_posterior_index\": []},\n",
    "           \"meanbax\": {\"n_obtained\": [], \"jaccard_posterior_index\": []},\n",
    "           \"infobax\": {\"n_obtained\": [], \"jaccard_posterior_index\": []}}\n",
    "\n",
    "\n",
    "# Baseling for random sampling without replacement \n",
    "random_sampling = [random_sampling_no_replace(len(X), len(true_target_ids), n) for n in range(n_initial, n_iters)]\n",
    "\n",
    "# Baseline for best possible acquisition (i.e. acquire a target point at each iteration; need an \"oracle\" to do this)\n",
    "if n_iters <= len(true_target_ids):\n",
    "    best_possible_n_obtained = np.arange(n_initial, n_iters + n_initial)\n",
    "else:\n",
    "    best_possible_n_obtained = list(np.arange(n_initial,len(true_target_ids))) + list(len(true_target_ids)*np.ones(n_iters + n_initial - len(true_target_ids)))\n",
    "\n",
    "# Acquisition functions that use BAX for subset estimation \n",
    "strategies = ['infobax', 'mixed', 'meanbax']\n",
    "\n",
    "# Calculate hypers based on the entire dataset; this is not possible in a real experiment but allows us to compare acquisition fn to acquisition fn \n",
    "if fixed_hypers:\n",
    "    kernel_list = fit_hypers(x_train=X, y_train=Y, kernel_list=kernel_initial_list, n_restarts_optimizer=1)\n",
    "\n",
    "for strategy in strategies:\n",
    "    for j in range(n_repeats): # to see variance w.r.t initial datapoint choice \n",
    "        np.random.seed(j)\n",
    "        train_indices = list(np.random.choice(all_ids, n_initial))    \n",
    "        x_train = X[train_indices]\n",
    "        y_train = Y[train_indices]\n",
    "        \n",
    "        collected_ids = list(train_indices)\n",
    "        n_obtained_list = [] \n",
    "        jaccard_posterior_list = [] \n",
    "\n",
    "        for i in tqdm(range(n_iters)):\n",
    "\n",
    "            # Adaptive hyperparameter fitting\n",
    "            if (i % adaptive_fit_freq == 0) and (fixed_hypers == False):\n",
    "                kernel_list = fit_hypers(x_train=x_train, y_train=y_train, kernel_list=kernel_initial_list)\n",
    "            \n",
    "            # Define GP model with fixed, fitted hypers. Note, we need this to be fixed so that all the n_posterior models for InfoBAX have the same kernel\n",
    "            multi_gpr = MGPR(kernel_list=kernel_list)\n",
    "\n",
    "            # Acquire next index \n",
    "            x_train, y_train, model, collected_ids, acquisition_function = run_acquisition(x_train, y_train, X, Y, strategy, algorithm, multi_gpr, collected_ids, n_posterior_samples)\n",
    "\n",
    "            # Calculate metrics \n",
    "            posterior_mean, posterior_std = model.predict(X)\n",
    "            predicted_target_ids = algorithm.identify_subspace(x=X, y=posterior_mean)\n",
    "            n_obtained_list.append(get_n_obtained(collected_ids, true_target_ids))\n",
    "            jaccard_posterior_list.append(get_jaccard_posterior(predicted_target_ids, true_target_ids))\n",
    "\n",
    "            if (i % plot_frequency == 0) and (plotting) and (i != 0): \n",
    "                plot_iteration_results(X, Y, x_scaler, y_scaler, collected_ids, true_target_ids, predicted_target_ids, acquisition_function, n_obtained_list, jaccard_posterior_list, best_possible_n_obtained, random_sampling)\n",
    "\n",
    "        metrics[strategy]['n_obtained'].append(n_obtained_list)\n",
    "        metrics[strategy]['jaccard_posterior_index'].append(jaccard_posterior_list)\n",
    "\n",
    "plot_final_metrics(n_iters, metrics, strategies, best_possible_n_obtained, random_sampling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "89b5c5be7d9a5b6c117ecb4d0f9593b952cdb99d9e5b93dbe620fac69234b982"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
